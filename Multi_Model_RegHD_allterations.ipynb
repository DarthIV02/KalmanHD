{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Research_Final.DatasetLoader_mine2 import DatasetLoader\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------\n",
      "Dataset name:  SanFranciscoTraffic\n",
      "Dataset contains missing values?  False\n",
      "--------------------------\n",
      "---------------------------------------------------\n",
      "Dataset name:  SanFranciscoTraffic\n",
      "Dataset contains missing values?  False\n",
      "--------------------------\n",
      "(862, 104)\n"
     ]
    }
   ],
   "source": [
    "parent = 'multipletimeseriesforecasting/preprocessed-data/'\n",
    "\n",
    "path = os.path.join(parent, 'SanFranciscoTraffic/traffic_weekly_dataset.tsf')\n",
    "\n",
    "dl = DatasetLoader('SanFranciscoTraffic', path)\n",
    "\n",
    "matrix_1_original = dl.dataset_load_and_preprocess(\"original\")\n",
    "matrix_1_norm = dl.dataset_load_and_preprocess(\"normalized\")\n",
    "print(matrix_1_norm.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample_len total 31\n",
      "[24 39 52 27 44  2 21 62 41 50 38 54 35 26 57 49  3 40 36 10 56 19 34 60] [17 55 53 48 33 51 31]\n"
     ]
    }
   ],
   "source": [
    "sample_len = int(matrix_1_norm.shape[1]*(0.3))\n",
    "print(\"Sample_len total\", sample_len)\n",
    "\n",
    "np.random.seed(1)\n",
    "sets = np.random.choice(matrix_1_norm.shape[1]-40, int(sample_len), replace=False)\n",
    "sets_training, sets_testing = sets[:int(len(sets)*.8)], sets[int(len(sets)*.8):]\n",
    "print(sets_training, sets_testing)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regular Multimodel HD with time series encoding(permutation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [04:03<00:00, 243.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training mean squared error of 0.024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as data\n",
    "\n",
    "# Note: this example requires the torchmetrics library: https://torchmetrics.readthedocs.io\n",
    "import torchmetrics\n",
    "from tqdm import tqdm\n",
    "\n",
    "from torchhd import functional\n",
    "from torchhd import embeddings\n",
    "from torchhd import cos_similarity\n",
    "\n",
    "from scipy.special import softmax\n",
    "\n",
    "import time\n",
    "\n",
    "d=10000\n",
    "models = 8\n",
    "\n",
    "# Model based on RegHD application for Single model regression -> No comparing which cluster\n",
    "class MultiModel_With_NonLinear_Sin(nn.Module):\n",
    "    def __init__(self, num_classes, size):\n",
    "        super(MultiModel_With_NonLinear_Sin, self).__init__()\n",
    "\n",
    "        self.lr = 0.00001 # alpha\n",
    "        self.M = torch.zeros(models, d).double() # Model initializes in 0\n",
    "        self.project = embeddings.Projection(1, d).double() # 5 features, 10000 dimensions = hypervectors like weights?\n",
    "        self.project.weight.data.normal_(0, 1) # Normal distributions mean=0.0, std=1.0\n",
    "        self.bias = nn.parameter.Parameter(torch.empty(d), requires_grad=False)\n",
    "        self.bias.data.uniform_(0, 2 * math.pi) # bias\n",
    "        self.cluster = functional.random_hv(models, d)\n",
    "\n",
    "    def encode(self, x): # encoding a value\n",
    "        vector_hv = torch.zeros(d)\n",
    "        for i in range(len(x)):\n",
    "            x[i] = float(x[i])\n",
    "            enc = self.project(torch.tensor([x[i]]))\n",
    "            permute = functional.permute(enc, shifts=i)\n",
    "            vector_hv = functional.bundle(vector_hv,permute)\n",
    "        return functional.hard_quantize(vector_hv)\n",
    "\n",
    "    def model_update(self, x, y): # update # y = no hv\n",
    "        x = torch.reshape(x, (1,d))\n",
    "        confidence = np.transpose(softmax(cos_similarity(self.cluster, x))) # Compare input with cluster\n",
    "        model_result = F.linear(x, self.M).type(torch.FloatTensor)\n",
    "        update = self.M + (float(self.lr) * float(y - F.linear(confidence, model_result)) * x) # Model + alpha*(Error)*(x)\n",
    "        #update = update.mean(0) # Mean by columns\n",
    "        self.M = update # New \n",
    "        # update cluster center?\n",
    "        center = [num.item() for num in confidence[0]].index(max(confidence[0]).item())\n",
    "        self.cluster[center] = self.cluster[center] + (1-max(confidence[0])) * x\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        enc = torch.reshape(self.encode(x), (1,d))\n",
    "        confidence = np.transpose(softmax(cos_similarity(self.cluster, enc))) # Compare input with cluster\n",
    "        model_result = F.linear(enc, self.M).type(torch.FloatTensor)\n",
    "        res = F.linear(confidence, model_result) # Multiply enc (x) * weights (Model) = Dot product\n",
    "        return res # Return the resolutions\n",
    "    \n",
    "model = MultiModel_With_NonLinear_Sin(2, 40) # 1 class, 5\n",
    "#model = model.to(device)\n",
    "\n",
    "#mse = torchmetrics.MeanSquaredError()\n",
    "    \n",
    "# Model training\n",
    "\n",
    "start_time = time.time()\n",
    "#main()\n",
    "#print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "\n",
    "## TRIED ONE ITERATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [04:04<00:00, 244.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training mean squared error of 0.022\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad(): # disabled gradient calculation because were doing it manually\n",
    "    for _ in tqdm(range(1)): # Number of iterations for all the samples\n",
    "        mse = torchmetrics.MeanSquaredError()\n",
    "        for i in sets_training:\n",
    "            pred = []\n",
    "            samples = matrix_1_norm[:, i:i+40]\n",
    "            labels = matrix_1_norm[:, i+40]\n",
    "            #print(f\"sample: {samples}, label:{labels}\")\n",
    "            #samples = samples.to(device) # pass sample and label (1 at a time)\n",
    "            #labels = labels.to(device)\n",
    "            \n",
    "            for n in range(samples.shape[0]):\n",
    "                label = torch.tensor(labels[n])\n",
    "                sample = torch.tensor(samples[n, :])\n",
    "                #print(x)\n",
    "                #samples = \n",
    "                samples_hv = model.encode(sample) # Encode the inputs\n",
    "                #print(f\"sample_hv:{samples_hv}\")\n",
    "                model.model_update(samples_hv, label) # Pass input and label to train\n",
    "\n",
    "                predictions_testing = model(sample) # Pass samples from test to model (forward function)\n",
    "                pred.append(predictions_testing[0])\n",
    "                #predictions_testing = predictions_testing\n",
    "                #label = label\n",
    "                mse.update(predictions_testing[0], label.unsqueeze(dim=0))\n",
    "                #mse.update(predictions_testing.cpu(), label)\n",
    "\n",
    "        print(f\"Training mean squared error of {(mse.compute().item()):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:35<00:00,  5.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing mean squared error of testing 0.039\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "pred_multihd = []\n",
    "original_hd = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    mse = torchmetrics.MeanSquaredError()\n",
    "    for i in tqdm(sets_testing):\n",
    "        pred = []\n",
    "        samples = matrix_1_norm[:, i:i+40]\n",
    "        labels = matrix_1_norm[:, i+40]\n",
    "        for n in range(samples.shape[0]):\n",
    "            label = torch.tensor(labels[n])\n",
    "            sample = torch.tensor(samples[n, :])\n",
    "            # Pass samples from test to model (forward function)\n",
    "            predictions = model(sample)\n",
    "            pred.append(predictions[0])\n",
    "            # predictions = predictions * TARGET_STD + TARGET_MEAN # What is target\n",
    "            # labels = labels * TARGET_STD + TARGET_MEAN\n",
    "            mse.update(predictions[0], label.unsqueeze(dim=0))\n",
    "            # dif_hd.append(np.absolute(label-predictions))\n",
    "            pred_multihd.append(predictions)\n",
    "            original_hd.append(label)\n",
    "\n",
    "    print(\n",
    "        f\"Testing mean squared error of testing {(mse.compute().item()):.3f}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mltimodal RegHD with just one cluster per prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [01:23<00:00, 83.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training mean squared error of 0.022\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as data\n",
    "\n",
    "# Note: this example requires the torchmetrics library: https://torchmetrics.readthedocs.io\n",
    "import torchmetrics\n",
    "from tqdm import tqdm\n",
    "\n",
    "from torchhd import functional\n",
    "from torchhd import embeddings\n",
    "from torchhd import cos_similarity\n",
    "\n",
    "from scipy.special import softmax\n",
    "\n",
    "import time\n",
    "\n",
    "d=10000\n",
    "models = 8\n",
    "\n",
    "# Model based on RegHD application for Single model regression -> No comparing which cluster\n",
    "class MultiModel_With_NonLinear_Sin(nn.Module):\n",
    "    def __init__(self, num_classes, size):\n",
    "        super(MultiModel_With_NonLinear_Sin, self).__init__()\n",
    "\n",
    "        self.lr = 0.00001 # alpha\n",
    "        self.M = torch.zeros(models, d).double() # Model initializes in 0\n",
    "        self.project = embeddings.Projection(size, d).double() # 5 features, 10000 dimensions = hypervectors like weights?\n",
    "        self.project.weight.data.normal_(0, 1) # Normal distributions mean=0.0, std=1.0\n",
    "        self.bias = nn.parameter.Parameter(torch.empty(d), requires_grad=False)\n",
    "        self.bias.data.uniform_(0, 2 * math.pi) # bias\n",
    "        self.cluster = functional.random_hv(models, d)\n",
    "\n",
    "    def encode(self, x): # encoding a value\n",
    "        for i in range(len(x)):\n",
    "            x[i] = float(x[i])\n",
    "        enc = self.project(x)\n",
    "        sample_hv = torch.cos(enc + self.bias) * torch.sin(enc) \n",
    "        return functional.hard_quantize(sample_hv)\n",
    "\n",
    "    def model_update(self, x, y): # update # y = no hv\n",
    "        x = torch.reshape(x, (1,d))\n",
    "        confidence = np.transpose(softmax(cos_similarity(self.cluster, x))) # Compare input with cluster\n",
    "        center = [num.item() for num in confidence[0]].index(max(confidence[0]).item())\n",
    "        update = self.M[center] + (float(self.lr) * float(y - F.linear(x, self.M[center])) * x) # Model + alpha*(Error)*(x)\n",
    "        #update = update.mean(0) # Mean by columns\n",
    "        self.M[center] = update # New \n",
    "        # update cluster center?\n",
    "        \n",
    "        self.cluster[center] = self.cluster[center] + (1-max(confidence[0])) * x\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        enc = torch.reshape(self.encode(x), (1,d))\n",
    "        confidence = np.transpose(softmax(cos_similarity(self.cluster, enc)))\n",
    "        center = [num.item() for num in confidence[0]].index(max(confidence[0]).item())\n",
    "        #confidence = np.transpose(softmax(cos_similarity(self.cluster, enc))) # Compare input with cluster\n",
    "        res = F.linear(enc, self.M[center])\n",
    "        #res = F.linear(confidence, model_result) # Multiply enc (x) * weights (Model) = Dot product\n",
    "        return res # Return the resolutions\n",
    "    \n",
    "model = MultiModel_With_NonLinear_Sin(2, 40) # 1 class, 5\n",
    "#model = model.to(device)\n",
    "\n",
    "#mse = torchmetrics.MeanSquaredError()\n",
    "    \n",
    "# Model training\n",
    "\n",
    "start_time = time.time()\n",
    "#main()\n",
    "#print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [01:21<00:00, 81.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training mean squared error of 0.015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad(): # disabled gradient calculation because were doing it manually\n",
    "    for _ in tqdm(range(1)): # Number of iterations for all the samples\n",
    "        mse = torchmetrics.MeanSquaredError()\n",
    "        for i in sets_training:\n",
    "            pred = []\n",
    "            samples = matrix_1_norm[:, i:i+40]\n",
    "            labels = matrix_1_norm[:, i+40]\n",
    "            #print(f\"sample: {samples}, label:{labels}\")\n",
    "            #samples = samples.to(device) # pass sample and label (1 at a time)\n",
    "            #labels = labels.to(device)\n",
    "            \n",
    "            for n in range(samples.shape[0]):\n",
    "                label = torch.tensor(labels[n])\n",
    "                sample = torch.tensor(samples[n, :])\n",
    "                #print(x)\n",
    "                #samples = \n",
    "                samples_hv = model.encode(sample) # Encode the inputs\n",
    "                #print(f\"sample_hv:{samples_hv}\")\n",
    "                model.model_update(samples_hv, label) # Pass input and label to train\n",
    "\n",
    "                predictions_testing = model(sample) # Pass samples from test to model (forward function)\n",
    "                pred.append(predictions_testing)\n",
    "                #predictions_testing = predictions_testing\n",
    "                #label = label\n",
    "                mse.update(predictions_testing, label.unsqueeze(dim=0))\n",
    "                #mse.update(predictions_testing.cpu(), label)\n",
    "\n",
    "        print(f\"Training mean squared error of {(mse.compute().item()):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:11<00:00,  1.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing mean squared error of testing 0.027\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "pred_multihd = []\n",
    "original_hd = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    mse = torchmetrics.MeanSquaredError()\n",
    "    for i in tqdm(sets_testing):\n",
    "        pred = []\n",
    "        samples = matrix_1_norm[:, i:i+40]\n",
    "        labels = matrix_1_norm[:, i+40]\n",
    "        for n in range(samples.shape[0]):\n",
    "            label = torch.tensor(labels[n])\n",
    "            sample = torch.tensor(samples[n, :])\n",
    "            # Pass samples from test to model (forward function)\n",
    "            predictions = model(sample)\n",
    "            pred.append(predictions)\n",
    "            # predictions = predictions * TARGET_STD + TARGET_MEAN # What is target\n",
    "            # labels = labels * TARGET_STD + TARGET_MEAN\n",
    "            mse.update(predictions, label.unsqueeze(dim=0))\n",
    "            # dif_hd.append(np.absolute(label-predictions))\n",
    "            pred_multihd.append(predictions)\n",
    "            original_hd.append(label)\n",
    "\n",
    "    print(\n",
    "        f\"Testing mean squared error of testing {(mse.compute().item()):.3f}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's combine both just for the sake of it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as data\n",
    "\n",
    "# Note: this example requires the torchmetrics library: https://torchmetrics.readthedocs.io\n",
    "import torchmetrics\n",
    "from tqdm import tqdm\n",
    "\n",
    "from torchhd import functional\n",
    "from torchhd import embeddings\n",
    "from torchhd import cos_similarity\n",
    "\n",
    "from scipy.special import softmax\n",
    "\n",
    "import time\n",
    "\n",
    "d=10000\n",
    "models = 8\n",
    "\n",
    "# Model based on RegHD application for Single model regression -> No comparing which cluster\n",
    "class MultiModel_With_NonLinear_Sin(nn.Module):\n",
    "    def __init__(self, num_classes, size):\n",
    "        super(MultiModel_With_NonLinear_Sin, self).__init__()\n",
    "\n",
    "        self.lr = 0.00001 # alpha\n",
    "        self.M = torch.zeros(models, d).double() # Model initializes in 0\n",
    "        self.project = embeddings.Projection(1, d).double() # 5 features, 10000 dimensions = hypervectors like weights?\n",
    "        self.project.weight.data.normal_(0, 1) # Normal distributions mean=0.0, std=1.0\n",
    "        self.bias = nn.parameter.Parameter(torch.empty(d), requires_grad=False)\n",
    "        self.bias.data.uniform_(0, 2 * math.pi) # bias\n",
    "        self.cluster = functional.random_hv(models, d)\n",
    "\n",
    "    def encode(self, x): # encoding a value\n",
    "        vector_hv = torch.zeros(d)\n",
    "        for i in range(len(x)):\n",
    "            x[i] = float(x[i])\n",
    "            enc = self.project(torch.tensor([x[i]]))\n",
    "            permute = functional.permute(enc, shifts=i)\n",
    "            vector_hv = functional.bundle(vector_hv,permute)\n",
    "        return functional.hard_quantize(vector_hv)\n",
    "\n",
    "    def model_update(self, x, y): # update # y = no hv\n",
    "        x = torch.reshape(x, (1,d))\n",
    "        confidence = np.transpose(softmax(cos_similarity(self.cluster, x))) # Compare input with cluster\n",
    "        center = [num.item() for num in confidence[0]].index(max(confidence[0]).item())\n",
    "        print(center)\n",
    "        update = self.M[center] + (float(self.lr) * float(y - F.linear(x, self.M[center])) * x) # Model + alpha*(Error)*(x)\n",
    "        #update = update.mean(0) # Mean by columns\n",
    "        self.M[center] = update # New \n",
    "        # update cluster center?\n",
    "        \n",
    "        self.cluster[center] = self.cluster[center] + (1-max(confidence[0])) * x\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        enc = torch.reshape(self.encode(x), (1,d))\n",
    "        confidence = np.transpose(softmax(cos_similarity(self.cluster, enc)))\n",
    "        center = [num.item() for num in confidence[0]].index(max(confidence[0]).item())\n",
    "        #confidence = np.transpose(softmax(cos_similarity(self.cluster, enc))) # Compare input with cluster\n",
    "        res = F.linear(enc, self.M[center])\n",
    "        #res = F.linear(confidence, model_result) # Multiply enc (x) * weights (Model) = Dot product\n",
    "        return res # Return the resolutions\n",
    "    \n",
    "model = MultiModel_With_NonLinear_Sin(2, 40) # 1 class, 5\n",
    "#model = model.to(device)\n",
    "\n",
    "#mse = torchmetrics.MeanSquaredError()\n",
    "    \n",
    "# Model training\n",
    "\n",
    "start_time = time.time()\n",
    "#main()\n",
    "#print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:14<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n",
      "7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32md:\\Documents\\Escuela\\SEEL\\Multi_Model_RegHD_allterations.ipynb Cell 14\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Documents/Escuela/SEEL/Multi_Model_RegHD_allterations.ipynb#X16sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m \u001b[39m#print(f\"sample_hv:{samples_hv}\")\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Documents/Escuela/SEEL/Multi_Model_RegHD_allterations.ipynb#X16sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m model\u001b[39m.\u001b[39mmodel_update(samples_hv, label) \u001b[39m# Pass input and label to train\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/Documents/Escuela/SEEL/Multi_Model_RegHD_allterations.ipynb#X16sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m predictions_testing \u001b[39m=\u001b[39m model(sample) \u001b[39m# Pass samples from test to model (forward function)\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Documents/Escuela/SEEL/Multi_Model_RegHD_allterations.ipynb#X16sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m pred\u001b[39m.\u001b[39mappend(predictions_testing)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Documents/Escuela/SEEL/Multi_Model_RegHD_allterations.ipynb#X16sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m \u001b[39m#predictions_testing = predictions_testing\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Documents/Escuela/SEEL/Multi_Model_RegHD_allterations.ipynb#X16sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m \u001b[39m#label = label\u001b[39;00m\n",
      "File \u001b[1;32md:\\Aplicaciones\\Anaconda\\envs\\tensorflow_env\\lib\\site-packages\\torch\\nn\\modules\\module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "\u001b[1;32md:\\Documents\\Escuela\\SEEL\\Multi_Model_RegHD_allterations.ipynb Cell 14\u001b[0m in \u001b[0;36mMultiModel_With_NonLinear_Sin.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Documents/Escuela/SEEL/Multi_Model_RegHD_allterations.ipynb#X16sZmlsZQ%3D%3D?line=56'>57</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/Documents/Escuela/SEEL/Multi_Model_RegHD_allterations.ipynb#X16sZmlsZQ%3D%3D?line=57'>58</a>\u001b[0m     enc \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mreshape(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mencode(x), (\u001b[39m1\u001b[39m,d))\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Documents/Escuela/SEEL/Multi_Model_RegHD_allterations.ipynb#X16sZmlsZQ%3D%3D?line=58'>59</a>\u001b[0m     confidence \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mtranspose(softmax(cos_similarity(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcluster, enc)))\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Documents/Escuela/SEEL/Multi_Model_RegHD_allterations.ipynb#X16sZmlsZQ%3D%3D?line=59'>60</a>\u001b[0m     center \u001b[39m=\u001b[39m [num\u001b[39m.\u001b[39mitem() \u001b[39mfor\u001b[39;00m num \u001b[39min\u001b[39;00m confidence[\u001b[39m0\u001b[39m]]\u001b[39m.\u001b[39mindex(\u001b[39mmax\u001b[39m(confidence[\u001b[39m0\u001b[39m])\u001b[39m.\u001b[39mitem())\n",
      "\u001b[1;32md:\\Documents\\Escuela\\SEEL\\Multi_Model_RegHD_allterations.ipynb Cell 14\u001b[0m in \u001b[0;36mMultiModel_With_NonLinear_Sin.encode\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Documents/Escuela/SEEL/Multi_Model_RegHD_allterations.ipynb#X16sZmlsZQ%3D%3D?line=36'>37</a>\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(x)):\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Documents/Escuela/SEEL/Multi_Model_RegHD_allterations.ipynb#X16sZmlsZQ%3D%3D?line=37'>38</a>\u001b[0m     x[i] \u001b[39m=\u001b[39m \u001b[39mfloat\u001b[39m(x[i])\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/Documents/Escuela/SEEL/Multi_Model_RegHD_allterations.ipynb#X16sZmlsZQ%3D%3D?line=38'>39</a>\u001b[0m     enc \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mproject(torch\u001b[39m.\u001b[39;49mtensor([x[i]]))\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Documents/Escuela/SEEL/Multi_Model_RegHD_allterations.ipynb#X16sZmlsZQ%3D%3D?line=39'>40</a>\u001b[0m     permute \u001b[39m=\u001b[39m functional\u001b[39m.\u001b[39mpermute(enc, shifts\u001b[39m=\u001b[39mi)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Documents/Escuela/SEEL/Multi_Model_RegHD_allterations.ipynb#X16sZmlsZQ%3D%3D?line=40'>41</a>\u001b[0m     vector_hv \u001b[39m=\u001b[39m functional\u001b[39m.\u001b[39mbundle(vector_hv,permute)\n",
      "File \u001b[1;32md:\\Aplicaciones\\Anaconda\\envs\\tensorflow_env\\lib\\site-packages\\torch\\nn\\modules\\module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32md:\\Aplicaciones\\Anaconda\\envs\\tensorflow_env\\lib\\site-packages\\torchhd\\embeddings.py:291\u001b[0m, in \u001b[0;36mProjection.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    290\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: torch\u001b[39m.\u001b[39mTensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m torch\u001b[39m.\u001b[39mTensor:\n\u001b[1;32m--> 291\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mlinear(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight)\u001b[39m.\u001b[39mas_subclass(MAP)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "with torch.no_grad(): # disabled gradient calculation because were doing it manually\n",
    "    for _ in tqdm(range(1)): # Number of iterations for all the samples\n",
    "        mse = torchmetrics.MeanSquaredError()\n",
    "        for i in sets_training:\n",
    "            pred = []\n",
    "            samples = matrix_1_norm[:, i:i+40]\n",
    "            labels = matrix_1_norm[:, i+40]\n",
    "            #print(f\"sample: {samples}, label:{labels}\")\n",
    "            #samples = samples.to(device) # pass sample and label (1 at a time)\n",
    "            #labels = labels.to(device)\n",
    "            \n",
    "            for n in range(samples.shape[0]):\n",
    "                label = torch.tensor(labels[n])\n",
    "                sample = torch.tensor(samples[n, :])\n",
    "                #print(x)\n",
    "                #samples = \n",
    "                samples_hv = model.encode(sample) # Encode the inputs\n",
    "                #print(f\"sample_hv:{samples_hv}\")\n",
    "                model.model_update(samples_hv, label) # Pass input and label to train\n",
    "\n",
    "                predictions_testing = model(sample) # Pass samples from test to model (forward function)\n",
    "                pred.append(predictions_testing)\n",
    "                #predictions_testing = predictions_testing\n",
    "                #label = label\n",
    "                mse.update(predictions_testing, label.unsqueeze(dim=0))\n",
    "                #mse.update(predictions_testing.cpu(), label)\n",
    "\n",
    "        print(f\"Training mean squared error of {(mse.compute().item()):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:35<00:00,  5.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing mean squared error of testing 0.040\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "pred_multihd = []\n",
    "original_hd = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    mse = torchmetrics.MeanSquaredError()\n",
    "    for i in tqdm(sets_testing):\n",
    "        pred = []\n",
    "        samples = matrix_1_norm[:, i:i+40]\n",
    "        labels = matrix_1_norm[:, i+40]\n",
    "        for n in range(samples.shape[0]):\n",
    "            label = torch.tensor(labels[n])\n",
    "            sample = torch.tensor(samples[n, :])\n",
    "            # Pass samples from test to model (forward function)\n",
    "            predictions = model(sample)\n",
    "            pred.append(predictions)\n",
    "            # predictions = predictions * TARGET_STD + TARGET_MEAN # What is target\n",
    "            # labels = labels * TARGET_STD + TARGET_MEAN\n",
    "            mse.update(predictions, label.unsqueeze(dim=0))\n",
    "            # dif_hd.append(np.absolute(label-predictions))\n",
    "            pred_multihd.append(predictions)\n",
    "            original_hd.append(label)\n",
    "\n",
    "    print(\n",
    "        f\"Testing mean squared error of testing {(mse.compute().item()):.3f}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lets try to group he cluster by external factors only"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Timeseries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as data\n",
    "\n",
    "# Note: this example requires the torchmetrics library: https://torchmetrics.readthedocs.io\n",
    "import torchmetrics\n",
    "from tqdm import tqdm\n",
    "\n",
    "from torchhd import functional\n",
    "from torchhd import embeddings\n",
    "from torchhd import cos_similarity, bind\n",
    "\n",
    "from scipy.special import softmax\n",
    "\n",
    "import time\n",
    "\n",
    "d = 10000\n",
    "models = 8\n",
    "\n",
    "# Model based on RegHD application for Single model regression -> No comparing which cluster\n",
    "class MultiModel_With_Data(nn.Module):\n",
    "    def __init__(self, num_classes, size):\n",
    "        super(MultiModel_With_Data, self).__init__()\n",
    "\n",
    "        self.lr = 0.00001 # alpha\n",
    "        self.M = torch.zeros(models, d).double() # Model initializes in 0\n",
    "        self.project = embeddings.Projection(size, d).double() # 5 features, 10000 dimensions = hypervectors like weights?\n",
    "        self.project.weight.data.normal_(0, 1) # Normal distributions mean=0.0, std=1.0\n",
    "        self.project_int = embeddings.Projection(1, d).float()# 5 features, 10000 dimensions = hypervectors like weights?\n",
    "        self.project_int.weight.data.normal_(0, 1) # Normal distributions mean=0.0, std=1.0\n",
    "        self.bias = nn.parameter.Parameter(torch.empty(d), requires_grad=False)\n",
    "        self.bias.data.uniform_(0, 2 * math.pi) # bias\n",
    "        self.cluster = functional.random_hv(models, d)\n",
    "\n",
    "    def encode(self, x): # encoding a value\n",
    "        try:\n",
    "            for i in range(len(x)):\n",
    "                x[i] = float(x[i])\n",
    "            enc = self.project(x)\n",
    "        except:\n",
    "            enc = self.project_int(torch.tensor([x[0]]))            \n",
    "        sample_hv = torch.cos(enc + self.bias) * torch.sin(enc) \n",
    "        return functional.hard_quantize(sample_hv)\n",
    "\n",
    "    def model_update(self, x, y, ts): # update # y = no hv\n",
    "        x = torch.reshape(x, (1,d))\n",
    "        ts_enc = self.encode([ts])\n",
    "        confidence = np.transpose(softmax(cos_similarity(self.cluster, ts_enc))) # Compare input with cluster\n",
    "        center = [num.item() for num in confidence[0]].index(max(confidence[0]).item())\n",
    "        update = self.M[center] + (float(self.lr) * float(y - F.linear(x, self.M[center])) * x) # Model + alpha*(Error)*(x)\n",
    "        #update = update.mean(0) # Mean by columns\n",
    "        self.M[center] = update # New \n",
    "        # update cluster center?\n",
    "        \n",
    "        self.cluster[center] = self.cluster[center] + (1-max(confidence[0])) * ts_enc\n",
    "        \n",
    "\n",
    "    def forward(self, x, ts):\n",
    "        enc = torch.reshape(self.encode(x), (1,d))\n",
    "        confidence = np.transpose(softmax(cos_similarity(self.cluster, self.encode([ts]))))\n",
    "        center = [num.item() for num in confidence[0]].index(max(confidence[0]).item())\n",
    "        #confidence = np.transpose(softmax(cos_similarity(self.cluster, enc))) # Compare input with cluster\n",
    "        res = F.linear(enc, self.M[center])\n",
    "        #res = F.linear(confidence, model_result) # Multiply enc (x) * weights (Model) = Dot product\n",
    "        return res # Return the resolutions\n",
    "    \n",
    "model = MultiModel_With_Data(2, 40) # 1 class, 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [02:57<00:00, 177.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training mean squared error of 0.030\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad(): # disabled gradient calculation because were doing it manually\n",
    "    for _ in tqdm(range(1)): # Number of iterations for all the samples\n",
    "        mse = torchmetrics.MeanSquaredError()\n",
    "        for i in sets_training:\n",
    "            pred = []\n",
    "            samples = matrix_1_norm[:, i:i+40]\n",
    "            labels = matrix_1_norm[:, i+40]\n",
    "            #print(f\"sample: {samples}, label:{labels}\")\n",
    "            #samples = samples.to(device) # pass sample and label (1 at a time)\n",
    "            #labels = labels.to(device)\n",
    "            \n",
    "            for n in range(samples.shape[0]):\n",
    "                label = torch.tensor(labels[n])\n",
    "                sample = torch.tensor(samples[n, :])\n",
    "                #print(x)\n",
    "                #samples = \n",
    "                samples_hv = model.encode(sample) # Encode the inputs\n",
    "                #print(f\"sample_hv:{samples_hv}\")\n",
    "                model.model_update(samples_hv, label, n) # Pass input and label to train\n",
    "\n",
    "                predictions_testing = model(sample, n) # Pass samples from test to model (forward function)\n",
    "                pred.append(predictions_testing)\n",
    "                #predictions_testing = predictions_testing\n",
    "                #label = label\n",
    "                mse.update(predictions_testing, label.unsqueeze(dim=0))\n",
    "                #mse.update(predictions_testing.cpu(), label)\n",
    "\n",
    "        print(f\"Training mean squared error of {(mse.compute().item()):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:23<00:00,  3.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing mean squared error of testing 0.033\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "pred_multihd = []\n",
    "original_hd = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    mse = torchmetrics.MeanSquaredError()\n",
    "    for i in tqdm(sets_testing):\n",
    "        pred = []\n",
    "        samples = matrix_1_norm[:, i:i+40]\n",
    "        labels = matrix_1_norm[:, i+40]\n",
    "        for n in range(samples.shape[0]):\n",
    "            label = torch.tensor(labels[n])\n",
    "            sample = torch.tensor(samples[n, :])\n",
    "            # Pass samples from test to model (forward function)\n",
    "            predictions = model(sample, n)\n",
    "            pred.append(predictions)\n",
    "            # predictions = predictions * TARGET_STD + TARGET_MEAN # What is target\n",
    "            # labels = labels * TARGET_STD + TARGET_MEAN\n",
    "            mse.update(predictions, label.unsqueeze(dim=0))\n",
    "            # dif_hd.append(np.absolute(label-predictions))\n",
    "            pred_multihd.append(predictions)\n",
    "            original_hd.append(label)\n",
    "\n",
    "    print(\n",
    "        f\"Testing mean squared error of testing {(mse.compute().item()):.3f}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as data\n",
    "\n",
    "# Note: this example requires the torchmetrics library: https://torchmetrics.readthedocs.io\n",
    "import torchmetrics\n",
    "from tqdm import tqdm\n",
    "\n",
    "from torchhd import functional\n",
    "from torchhd import embeddings\n",
    "from torchhd import cos_similarity, bind\n",
    "\n",
    "from scipy.special import softmax\n",
    "\n",
    "import time\n",
    "\n",
    "d = 10000\n",
    "models = 8\n",
    "\n",
    "# Model based on RegHD application for Single model regression -> No comparing which cluster\n",
    "class MultiModel_With_Data(nn.Module):\n",
    "    def __init__(self, num_classes, size):\n",
    "        super(MultiModel_With_Data, self).__init__()\n",
    "\n",
    "        self.lr = 0.00001 # alpha\n",
    "        self.M = torch.zeros(models, d).double() # Model initializes in 0\n",
    "        self.project = embeddings.Projection(size, d).double() # 5 features, 10000 dimensions = hypervectors like weights?\n",
    "        self.project.weight.data.normal_(0, 1) # Normal distributions mean=0.0, std=1.0\n",
    "        self.project_int = embeddings.Projection(1, d).float()# 5 features, 10000 dimensions = hypervectors like weights?\n",
    "        self.project_int.weight.data.normal_(0, 1) # Normal distributions mean=0.0, std=1.0\n",
    "        self.bias = nn.parameter.Parameter(torch.empty(d), requires_grad=False)\n",
    "        self.bias.data.uniform_(0, 2 * math.pi) # bias\n",
    "        self.cluster = functional.random_hv(models, d)\n",
    "\n",
    "    def encode(self, x): # encoding a value\n",
    "        try:\n",
    "            for i in range(len(x)):\n",
    "                x[i] = float(x[i])\n",
    "            enc = self.project(x)\n",
    "        except:\n",
    "            enc = self.project_int(torch.tensor([x[0]]))            \n",
    "        sample_hv = torch.cos(enc + self.bias) * torch.sin(enc) \n",
    "        return functional.hard_quantize(sample_hv)\n",
    "\n",
    "    def model_update(self, x, y, ts): # update # y = no hv\n",
    "        x = torch.reshape(x, (1,d))\n",
    "        ts_enc = self.encode([ts])\n",
    "        confidence = np.transpose(softmax(cos_similarity(self.cluster, ts_enc))) # Compare input with cluster\n",
    "        center = [num.item() for num in confidence[0]].index(max(confidence[0]).item())\n",
    "        update = self.M[center] + (float(self.lr) * float(y - F.linear(x, self.M[center])) * x) # Model + alpha*(Error)*(x)\n",
    "        #update = update.mean(0) # Mean by columns\n",
    "        self.M[center] = update # New \n",
    "        # update cluster center?\n",
    "        \n",
    "        self.cluster[center] = self.cluster[center] + (1-max(confidence[0])) * ts_enc\n",
    "        \n",
    "\n",
    "    def forward(self, x, ts):\n",
    "        enc = torch.reshape(self.encode(x), (1,d))\n",
    "        confidence = np.transpose(softmax(cos_similarity(self.cluster, self.encode([ts]))))\n",
    "        center = [num.item() for num in confidence[0]].index(max(confidence[0]).item())\n",
    "        #confidence = np.transpose(softmax(cos_similarity(self.cluster, enc))) # Compare input with cluster\n",
    "        res = F.linear(enc, self.M[center])\n",
    "        #res = F.linear(confidence, model_result) # Multiply enc (x) * weights (Model) = Dot product\n",
    "        return res # Return the resolutions\n",
    "    \n",
    "model = MultiModel_With_Data(2, 40) # 1 class, 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [02:53<00:00, 173.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training mean squared error of 0.028\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad(): # disabled gradient calculation because were doing it manually\n",
    "    for _ in tqdm(range(1)): # Number of iterations for all the samples\n",
    "        mse = torchmetrics.MeanSquaredError()\n",
    "        for i in sets_training:\n",
    "            pred = []\n",
    "            samples = matrix_1_norm[:, i:i+40]\n",
    "            labels = matrix_1_norm[:, i+40]\n",
    "            #print(f\"sample: {samples}, label:{labels}\")\n",
    "            #samples = samples.to(device) # pass sample and label (1 at a time)\n",
    "            #labels = labels.to(device)\n",
    "            \n",
    "            for n in range(samples.shape[0]):\n",
    "                label = torch.tensor(labels[n])\n",
    "                sample = torch.tensor(samples[n, :])\n",
    "                #print(x)\n",
    "                #samples = \n",
    "                samples_hv = model.encode(sample) # Encode the inputs\n",
    "                #print(f\"sample_hv:{samples_hv}\")\n",
    "                model.model_update(samples_hv, label, i) # Pass input and label to train\n",
    "\n",
    "                predictions_testing = model(sample, i) # Pass samples from test to model (forward function)\n",
    "                pred.append(predictions_testing)\n",
    "                #predictions_testing = predictions_testing\n",
    "                #label = label\n",
    "                mse.update(predictions_testing, label.unsqueeze(dim=0))\n",
    "                #mse.update(predictions_testing.cpu(), label)\n",
    "\n",
    "        print(f\"Training mean squared error of {(mse.compute().item()):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:30<00:00,  4.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing mean squared error of testing 0.032\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "pred_multihd = []\n",
    "original_hd = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    mse = torchmetrics.MeanSquaredError()\n",
    "    for i in tqdm(sets_testing):\n",
    "        pred = []\n",
    "        samples = matrix_1_norm[:, i:i+40]\n",
    "        labels = matrix_1_norm[:, i+40]\n",
    "        for n in range(samples.shape[0]):\n",
    "            label = torch.tensor(labels[n])\n",
    "            sample = torch.tensor(samples[n, :])\n",
    "            # Pass samples from test to model (forward function)\n",
    "            predictions = model(sample, i)\n",
    "            pred.append(predictions)\n",
    "            # predictions = predictions * TARGET_STD + TARGET_MEAN # What is target\n",
    "            # labels = labels * TARGET_STD + TARGET_MEAN\n",
    "            mse.update(predictions, label.unsqueeze(dim=0))\n",
    "            # dif_hd.append(np.absolute(label-predictions))\n",
    "            pred_multihd.append(predictions)\n",
    "            original_hd.append(label)\n",
    "\n",
    "    print(\n",
    "        f\"Testing mean squared error of testing {(mse.compute().item()):.3f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a2579cda5598981a7d6f95b654f192908a972fd9b0a94ff6f67cbf4cdb5f0a73"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
